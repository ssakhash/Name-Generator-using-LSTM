{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be583fc",
   "metadata": {},
   "source": [
    "<h3>Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7ccfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c55b68",
   "metadata": {},
   "source": [
    "<h3>Manually performing OneHot Encoding on Alphabets and 'eon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43679c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = [\"eon\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "encoded_alphabets = np.zeros((len(alphabets), len(alphabets)))\n",
    "for i in range(len(alphabets)):\n",
    "    encoded_alphabets[i][i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c25e03",
   "metadata": {},
   "source": [
    "<h3>Reading Input Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b80daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in os.listdir():\n",
    "        filename, extension = os.path.splitext(files)\n",
    "        if extension == '.txt':\n",
    "            input_filename = files\n",
    "with open(input_filename) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "words = np.zeros((len(lines), 11), dtype='U16')\n",
    "\n",
    "for name_index in range(len(lines)):\n",
    "    name = lines[name_index].lower().strip()\n",
    "    for character_index in range(len(name)):\n",
    "        words[name_index][character_index] = name[character_index]\n",
    "    for empty_index in range(len(name), 11):\n",
    "        words[name_index][empty_index] = 'eon'\n",
    "        \n",
    "words_copy = deepcopy(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a11ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_output = deepcopy(words)\n",
    "for i in range(len(words_copy)):\n",
    "    temp_array = np.delete(words_copy[i], 0)\n",
    "    desired_output[i] = np.append(temp_array, 'eon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd51305",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.ones((2000, 11, 27), dtype = 'double')\n",
    "for name_index in range(len(words)):\n",
    "    for char_index in range(len(words[name_index])):\n",
    "        character = words[name_index][char_index]\n",
    "        encoded_index = alphabets.index(character)\n",
    "        inputs[name_index][char_index] = encoded_alphabets[encoded_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49184b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.ones((2000, 11, 27), dtype = 'double')\n",
    "for name_index in range(len(words)):\n",
    "    for char_index in range(len(words[name_index])):\n",
    "        character = words[name_index][char_index]\n",
    "        encoded_index = alphabets.index(character)\n",
    "        outputs[name_index][char_index] = encoded_alphabets[encoded_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eec85c",
   "metadata": {},
   "source": [
    "<h3>Creating Tensors for Inputs and Desired Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69812cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(inputs).float()\n",
    "outputs = torch.tensor(outputs).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e50dc4",
   "metadata": {},
   "source": [
    "<h3>Declaring Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a55f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return inputs[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0212ea4d",
   "metadata": {},
   "source": [
    "<h3>Initializing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe8eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = inputs, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be7fcc",
   "metadata": {},
   "source": [
    "<h3>Declaring Neural Network Layers for LSTM Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e46f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_1 = nn.LSTM(27, 27)\n",
    "        self.fc1 = nn.Linear(27, 27)\n",
    "        self.fc2 = nn.Linear(27, 27)\n",
    "        \n",
    "    def forward(self, output):\n",
    "        output, hidden = self.hidden_1(output)\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfa775",
   "metadata": {},
   "source": [
    "<h3>Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1eae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = (1e-4))\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40bb1b",
   "metadata": {},
   "source": [
    "<h3>Function to Return OneHot Encoded Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28421c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encodedvalue(input_character):\n",
    "    encodedvalue = []\n",
    "    for entry in input_character:\n",
    "        char_index = alphabets.index(entry)\n",
    "        encodedvalue.append(encoded_alphabets[char_index])\n",
    "    return encodedvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267970e",
   "metadata": {},
   "source": [
    "<h3>Function to Return Characters from OneHot Encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1bda410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charactervalue(obtained_output):\n",
    "    charactervalue = []\n",
    "    value, indices = torch.topk(obtained_output, 4, dim = 2)\n",
    "    x, y, z = indices.size()\n",
    "    random_number = np.random.random()\n",
    "    if random_number > 0.9:\n",
    "        rand_int = 0\n",
    "    elif random_number > 0.5 and random_number < 0.9:\n",
    "        rand_int = 1\n",
    "    elif random_number > 0.3 and random_number < 0.5:\n",
    "        rand_int = 2\n",
    "    else:\n",
    "        rand_int = 3      \n",
    "    if (alphabets[indices[0][-1][rand_int]]) == \"eon\":\n",
    "        flag = False\n",
    "        return charactervalue, flag\n",
    "    charactervalue.append(alphabets[indices[0][-1][rand_int]])\n",
    "    flag = True\n",
    "    return charactervalue, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f53407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anlelanlai\n",
      "anlaai\n",
      "aioa\n",
      "anlea\n",
      "anai\n",
      "anananlnla\n",
      "anlai\n",
      "aioii\n",
      "anla\n",
      "aiana\n",
      "aioe\n",
      "aaa\n",
      "aii\n",
      "anln\n",
      "aioaaia\n",
      "aioelelelann\n",
      "anlaia\n",
      "aiaa\n",
      "anlaioa\n",
      "aan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-d657cf9558c1>:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  encoded_input_tensor = torch.tensor(encoded_input).float()\n"
     ]
    }
   ],
   "source": [
    "output_tracker = []\n",
    "counter = 0\n",
    "while counter < 20:\n",
    "    flag = True\n",
    "    obtained_char = []\n",
    "    input_character = []\n",
    "    input_character.append(\"a\")\n",
    "    while flag == True:\n",
    "        encoded_input = get_encodedvalue(input_character)\n",
    "        encoded_input_tensor = torch.tensor(encoded_input).float()\n",
    "        output, hidden = model(encoded_input_tensor.unsqueeze(0))\n",
    "        obtained_char, flag = get_charactervalue(output)\n",
    "        input_character = input_character + obtained_char\n",
    "        if input_character[-1] == \"eon\":\n",
    "            flag = False\n",
    "        if len(input_character) > 11:\n",
    "             flag = False\n",
    "    for index, character in enumerate(input_character):\n",
    "        if index == (len(input_character) - 1):\n",
    "            if character == input_character[index - 1]:\n",
    "                continue\n",
    "        elif index == 0:\n",
    "            if character == input_character[index + 1]:\n",
    "                continue\n",
    "        elif character == input_character[index + 1]:\n",
    "            continue\n",
    "        elif character == input_character[index - 1]:\n",
    "            continue\n",
    "    if (''.join(input_character)) in output_tracker:\n",
    "        continue\n",
    "    if (len(''.join(input_character)) < 3):\n",
    "        continue\n",
    "    print(''.join(input_character))\n",
    "    output_tracker.append(str(''.join(input_character)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39bd138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xcyn\n",
      "xdd\n",
      "xxc\n",
      "xdt\n",
      "xsroa\n",
      "xxcye\n",
      "xcn\n",
      "xxxccnlna\n",
      "xcnla\n",
      "xdia\n",
      "xxd\n",
      "xxxc\n",
      "xxcynln\n",
      "xsioellnana\n",
      "xcyeln\n",
      "xxdi\n",
      "xsriaa\n",
      "xxxd\n",
      "xdtt\n",
      "xxdiioan\n"
     ]
    }
   ],
   "source": [
    "output_tracker = []\n",
    "counter = 0\n",
    "while counter < 20:\n",
    "    flag = True\n",
    "    obtained_char = []\n",
    "    input_character = []\n",
    "    input_character.append(\"x\")\n",
    "    while flag == True:\n",
    "        encoded_input = get_encodedvalue(input_character)\n",
    "        encoded_input_tensor = torch.tensor(encoded_input).float()\n",
    "        output, hidden = model(encoded_input_tensor.unsqueeze(0))\n",
    "        obtained_char, flag = get_charactervalue(output)\n",
    "        input_character = input_character + obtained_char\n",
    "        if input_character[-1] == \"eon\":\n",
    "            flag = False\n",
    "        if len(input_character) > 11:\n",
    "             flag = False\n",
    "    if (''.join(input_character)) in output_tracker:\n",
    "        continue\n",
    "    if (len(''.join(input_character)) < 3):\n",
    "        continue\n",
    "    print(''.join(input_character))\n",
    "    output_tracker.append(str(''.join(input_character)))\n",
    "    counter +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
